{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HjWmMQFp605cvy6f9N6OT8bj363I-Rf8",
      "authorship_tag": "ABX9TyPAzwXuuP8akrrMEZN+0wDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishareddy04/ML_CSE_21206A/blob/ML_LAB_CODES/ML_LAB7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RPrfOCwsNJ-c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('t5_train (1).xlsx')"
      ],
      "metadata": {
        "id": "vVWNme9RmBRp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "jNyrqNDz8wqa",
        "outputId": "22ccc7c1-7cf1-4af0-a1f7-b8f50df1c32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0.1    Unnamed: 0       embed_0       embed_1       embed_2  \\\n",
              "0                0  0.000000e+00  5.758212e+07  6.776345e+07  2.800258e+07   \n",
              "1        100000000  8.880995e+04  3.119097e+07  3.410519e+07  3.968865e+07   \n",
              "2        200000000  1.776199e+05  3.847380e+07  6.444416e+07  5.426541e+07   \n",
              "3        300000000  2.664298e+05  2.607828e+07  2.149011e+07  2.634352e+07   \n",
              "4        400000000  3.552398e+05  3.036039e+07  3.340103e+07  2.486513e+07   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1122  112200000000  9.964476e+07  6.174452e+07  3.934451e+07  3.769432e+07   \n",
              "1123  112300000000  9.973357e+07  6.060619e+07  3.793623e+07  3.743693e+07   \n",
              "1124  112400000000  9.982238e+07  6.540321e+07  4.104826e+07  4.502261e+07   \n",
              "1125  112500000000  9.991119e+07  6.864575e+07  3.401918e+07  3.546503e+07   \n",
              "1126  112600000000  1.000000e+08  7.559972e+07  2.625881e+07  3.440408e+07   \n",
              "\n",
              "           embed_3       embed_4       embed_5       embed_6       embed_7  \\\n",
              "0     6.299759e+07  6.978351e+07  1.711683e+07  5.645584e+07  7.937437e+07   \n",
              "1     6.026731e+07  6.183475e+07  3.061917e+07  8.182981e+07  6.866750e+07   \n",
              "2     4.964486e+07  6.064547e+07  3.750610e+07  3.918242e+07  8.528705e+07   \n",
              "3     6.323442e+07  5.654922e+07  3.232962e+07  6.189213e+07  5.450312e+07   \n",
              "4     5.551810e+07  6.740773e+07  2.651439e+07  6.164045e+07  9.178669e+07   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1122  6.154342e+07  5.941496e+07  4.076067e+07  2.463756e+07  3.581907e+07   \n",
              "1123  5.761607e+07  5.954448e+07  3.602340e+07  2.998996e+07  3.660076e+07   \n",
              "1124  6.211483e+07  7.146898e+07  4.640262e+07  3.241480e+07  2.983658e+07   \n",
              "1125  5.827873e+07  6.182658e+07  3.608731e+07  2.447521e+07  3.322754e+07   \n",
              "1126  5.941596e+07  5.360437e+07  4.426308e+07  2.242577e+07  3.087278e+07   \n",
              "\n",
              "      ...     embed_758     embed_759     embed_760     embed_761  \\\n",
              "0     ...  2.761353e+07  6.929405e+07  4.151228e+07  5.909623e+07   \n",
              "1     ...  5.688703e+07  3.626266e+07  2.692882e+07  3.141667e+07   \n",
              "2     ...  6.649120e+07  8.044265e+07  5.063507e+07  6.075776e+07   \n",
              "3     ...  6.374082e+07  1.351830e+07  3.554108e+07  3.662709e+07   \n",
              "4     ...  7.475274e+07  6.132165e+07  4.784321e+07  2.864229e+07   \n",
              "...   ...           ...           ...           ...           ...   \n",
              "1122  ...  3.896961e+07  4.506058e+07  4.383869e+07  5.558857e+07   \n",
              "1123  ...  3.600460e+07  4.291674e+07  3.658945e+07  5.347316e+07   \n",
              "1124  ...  4.250043e+07  3.925247e+07  5.128983e+07  5.011916e+07   \n",
              "1125  ...  3.845901e+07  3.649167e+07  1.828804e+07  5.164256e+07   \n",
              "1126  ...  2.799557e+07  3.575177e+07  3.188954e+07  4.842805e+07   \n",
              "\n",
              "         embed_762     embed_763     embed_764     embed_765     embed_766  \\\n",
              "0     3.765414e+07  4.017201e+07  6.018143e+07  3.977631e+07  4.195800e+07   \n",
              "1     8.218112e+07  6.342494e+07  3.680709e+07  2.128675e+07  6.188865e+07   \n",
              "2     4.996887e+07  5.627393e+07  7.497355e+07  0.000000e+00  3.842391e+07   \n",
              "3     7.806034e+07  8.068278e+07  4.215658e+07  1.532215e+07  4.028508e+07   \n",
              "4     6.647345e+07  6.706953e+07  6.027831e+07  3.421864e+07  4.819099e+07   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1122  5.359720e+07  6.048844e+07  5.815135e+07  5.420333e+07  5.798462e+07   \n",
              "1123  5.364259e+07  5.595120e+07  5.821297e+07  5.862623e+07  5.566659e+07   \n",
              "1124  4.752961e+07  6.417437e+07  5.967216e+07  5.021099e+07  6.267431e+07   \n",
              "1125  4.947513e+07  4.944955e+07  5.508058e+07  6.840924e+07  5.894529e+07   \n",
              "1126  4.718500e+07  3.960551e+07  5.850908e+07  6.342944e+07  5.645050e+07   \n",
              "\n",
              "         embed_767  \n",
              "0     3.689091e+07  \n",
              "1     4.039343e+07  \n",
              "2     7.024441e+07  \n",
              "3     4.792073e+07  \n",
              "4     6.838880e+07  \n",
              "...            ...  \n",
              "1122  1.343794e+07  \n",
              "1123  1.343368e+07  \n",
              "1124  1.415758e+07  \n",
              "1125  6.818253e+06  \n",
              "1126  1.678831e+07  \n",
              "\n",
              "[1127 rows x 770 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd476088-9c18-4117-87b5-2da67efab49e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>embed_0</th>\n",
              "      <th>embed_1</th>\n",
              "      <th>embed_2</th>\n",
              "      <th>embed_3</th>\n",
              "      <th>embed_4</th>\n",
              "      <th>embed_5</th>\n",
              "      <th>embed_6</th>\n",
              "      <th>embed_7</th>\n",
              "      <th>...</th>\n",
              "      <th>embed_758</th>\n",
              "      <th>embed_759</th>\n",
              "      <th>embed_760</th>\n",
              "      <th>embed_761</th>\n",
              "      <th>embed_762</th>\n",
              "      <th>embed_763</th>\n",
              "      <th>embed_764</th>\n",
              "      <th>embed_765</th>\n",
              "      <th>embed_766</th>\n",
              "      <th>embed_767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.758212e+07</td>\n",
              "      <td>6.776345e+07</td>\n",
              "      <td>2.800258e+07</td>\n",
              "      <td>6.299759e+07</td>\n",
              "      <td>6.978351e+07</td>\n",
              "      <td>1.711683e+07</td>\n",
              "      <td>5.645584e+07</td>\n",
              "      <td>7.937437e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>2.761353e+07</td>\n",
              "      <td>6.929405e+07</td>\n",
              "      <td>4.151228e+07</td>\n",
              "      <td>5.909623e+07</td>\n",
              "      <td>3.765414e+07</td>\n",
              "      <td>4.017201e+07</td>\n",
              "      <td>6.018143e+07</td>\n",
              "      <td>3.977631e+07</td>\n",
              "      <td>4.195800e+07</td>\n",
              "      <td>3.689091e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100000000</td>\n",
              "      <td>8.880995e+04</td>\n",
              "      <td>3.119097e+07</td>\n",
              "      <td>3.410519e+07</td>\n",
              "      <td>3.968865e+07</td>\n",
              "      <td>6.026731e+07</td>\n",
              "      <td>6.183475e+07</td>\n",
              "      <td>3.061917e+07</td>\n",
              "      <td>8.182981e+07</td>\n",
              "      <td>6.866750e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>5.688703e+07</td>\n",
              "      <td>3.626266e+07</td>\n",
              "      <td>2.692882e+07</td>\n",
              "      <td>3.141667e+07</td>\n",
              "      <td>8.218112e+07</td>\n",
              "      <td>6.342494e+07</td>\n",
              "      <td>3.680709e+07</td>\n",
              "      <td>2.128675e+07</td>\n",
              "      <td>6.188865e+07</td>\n",
              "      <td>4.039343e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200000000</td>\n",
              "      <td>1.776199e+05</td>\n",
              "      <td>3.847380e+07</td>\n",
              "      <td>6.444416e+07</td>\n",
              "      <td>5.426541e+07</td>\n",
              "      <td>4.964486e+07</td>\n",
              "      <td>6.064547e+07</td>\n",
              "      <td>3.750610e+07</td>\n",
              "      <td>3.918242e+07</td>\n",
              "      <td>8.528705e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>6.649120e+07</td>\n",
              "      <td>8.044265e+07</td>\n",
              "      <td>5.063507e+07</td>\n",
              "      <td>6.075776e+07</td>\n",
              "      <td>4.996887e+07</td>\n",
              "      <td>5.627393e+07</td>\n",
              "      <td>7.497355e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.842391e+07</td>\n",
              "      <td>7.024441e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300000000</td>\n",
              "      <td>2.664298e+05</td>\n",
              "      <td>2.607828e+07</td>\n",
              "      <td>2.149011e+07</td>\n",
              "      <td>2.634352e+07</td>\n",
              "      <td>6.323442e+07</td>\n",
              "      <td>5.654922e+07</td>\n",
              "      <td>3.232962e+07</td>\n",
              "      <td>6.189213e+07</td>\n",
              "      <td>5.450312e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>6.374082e+07</td>\n",
              "      <td>1.351830e+07</td>\n",
              "      <td>3.554108e+07</td>\n",
              "      <td>3.662709e+07</td>\n",
              "      <td>7.806034e+07</td>\n",
              "      <td>8.068278e+07</td>\n",
              "      <td>4.215658e+07</td>\n",
              "      <td>1.532215e+07</td>\n",
              "      <td>4.028508e+07</td>\n",
              "      <td>4.792073e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>400000000</td>\n",
              "      <td>3.552398e+05</td>\n",
              "      <td>3.036039e+07</td>\n",
              "      <td>3.340103e+07</td>\n",
              "      <td>2.486513e+07</td>\n",
              "      <td>5.551810e+07</td>\n",
              "      <td>6.740773e+07</td>\n",
              "      <td>2.651439e+07</td>\n",
              "      <td>6.164045e+07</td>\n",
              "      <td>9.178669e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>7.475274e+07</td>\n",
              "      <td>6.132165e+07</td>\n",
              "      <td>4.784321e+07</td>\n",
              "      <td>2.864229e+07</td>\n",
              "      <td>6.647345e+07</td>\n",
              "      <td>6.706953e+07</td>\n",
              "      <td>6.027831e+07</td>\n",
              "      <td>3.421864e+07</td>\n",
              "      <td>4.819099e+07</td>\n",
              "      <td>6.838880e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1122</th>\n",
              "      <td>112200000000</td>\n",
              "      <td>9.964476e+07</td>\n",
              "      <td>6.174452e+07</td>\n",
              "      <td>3.934451e+07</td>\n",
              "      <td>3.769432e+07</td>\n",
              "      <td>6.154342e+07</td>\n",
              "      <td>5.941496e+07</td>\n",
              "      <td>4.076067e+07</td>\n",
              "      <td>2.463756e+07</td>\n",
              "      <td>3.581907e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>3.896961e+07</td>\n",
              "      <td>4.506058e+07</td>\n",
              "      <td>4.383869e+07</td>\n",
              "      <td>5.558857e+07</td>\n",
              "      <td>5.359720e+07</td>\n",
              "      <td>6.048844e+07</td>\n",
              "      <td>5.815135e+07</td>\n",
              "      <td>5.420333e+07</td>\n",
              "      <td>5.798462e+07</td>\n",
              "      <td>1.343794e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>112300000000</td>\n",
              "      <td>9.973357e+07</td>\n",
              "      <td>6.060619e+07</td>\n",
              "      <td>3.793623e+07</td>\n",
              "      <td>3.743693e+07</td>\n",
              "      <td>5.761607e+07</td>\n",
              "      <td>5.954448e+07</td>\n",
              "      <td>3.602340e+07</td>\n",
              "      <td>2.998996e+07</td>\n",
              "      <td>3.660076e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>3.600460e+07</td>\n",
              "      <td>4.291674e+07</td>\n",
              "      <td>3.658945e+07</td>\n",
              "      <td>5.347316e+07</td>\n",
              "      <td>5.364259e+07</td>\n",
              "      <td>5.595120e+07</td>\n",
              "      <td>5.821297e+07</td>\n",
              "      <td>5.862623e+07</td>\n",
              "      <td>5.566659e+07</td>\n",
              "      <td>1.343368e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1124</th>\n",
              "      <td>112400000000</td>\n",
              "      <td>9.982238e+07</td>\n",
              "      <td>6.540321e+07</td>\n",
              "      <td>4.104826e+07</td>\n",
              "      <td>4.502261e+07</td>\n",
              "      <td>6.211483e+07</td>\n",
              "      <td>7.146898e+07</td>\n",
              "      <td>4.640262e+07</td>\n",
              "      <td>3.241480e+07</td>\n",
              "      <td>2.983658e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>4.250043e+07</td>\n",
              "      <td>3.925247e+07</td>\n",
              "      <td>5.128983e+07</td>\n",
              "      <td>5.011916e+07</td>\n",
              "      <td>4.752961e+07</td>\n",
              "      <td>6.417437e+07</td>\n",
              "      <td>5.967216e+07</td>\n",
              "      <td>5.021099e+07</td>\n",
              "      <td>6.267431e+07</td>\n",
              "      <td>1.415758e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1125</th>\n",
              "      <td>112500000000</td>\n",
              "      <td>9.991119e+07</td>\n",
              "      <td>6.864575e+07</td>\n",
              "      <td>3.401918e+07</td>\n",
              "      <td>3.546503e+07</td>\n",
              "      <td>5.827873e+07</td>\n",
              "      <td>6.182658e+07</td>\n",
              "      <td>3.608731e+07</td>\n",
              "      <td>2.447521e+07</td>\n",
              "      <td>3.322754e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>3.845901e+07</td>\n",
              "      <td>3.649167e+07</td>\n",
              "      <td>1.828804e+07</td>\n",
              "      <td>5.164256e+07</td>\n",
              "      <td>4.947513e+07</td>\n",
              "      <td>4.944955e+07</td>\n",
              "      <td>5.508058e+07</td>\n",
              "      <td>6.840924e+07</td>\n",
              "      <td>5.894529e+07</td>\n",
              "      <td>6.818253e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>112600000000</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>7.559972e+07</td>\n",
              "      <td>2.625881e+07</td>\n",
              "      <td>3.440408e+07</td>\n",
              "      <td>5.941596e+07</td>\n",
              "      <td>5.360437e+07</td>\n",
              "      <td>4.426308e+07</td>\n",
              "      <td>2.242577e+07</td>\n",
              "      <td>3.087278e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>2.799557e+07</td>\n",
              "      <td>3.575177e+07</td>\n",
              "      <td>3.188954e+07</td>\n",
              "      <td>4.842805e+07</td>\n",
              "      <td>4.718500e+07</td>\n",
              "      <td>3.960551e+07</td>\n",
              "      <td>5.850908e+07</td>\n",
              "      <td>6.342944e+07</td>\n",
              "      <td>5.645050e+07</td>\n",
              "      <td>1.678831e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1127 rows × 770 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd476088-9c18-4117-87b5-2da67efab49e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd476088-9c18-4117-87b5-2da67efab49e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd476088-9c18-4117-87b5-2da67efab49e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ea17418-81b2-4d5b-9c3c-8f9f5c67db49\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ea17418-81b2-4d5b-9c3c-8f9f5c67db49')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ea17418-81b2-4d5b-9c3c-8f9f5c67db49 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.apply(lambda x: x*10000)\n",
        "arr = np.array(data)\n",
        "x = arr[:, 3:5]\n",
        "y = arr[:, [4]]\n",
        "y = y.astype('int')\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "print(x)\n",
        "print(\"\\n\",y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSXE7Nz79DEx",
        "outputId": "3baf1931-7b58-486c-be26-920d5d697e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[67763446.33492495 28002576.36981866]\n",
            " [34105194.46663083 39688652.15508664]\n",
            " [64444161.9627727  54265409.19666092]\n",
            " ...\n",
            " [41048263.67329707 45022611.46924686]\n",
            " [34019176.68232258 35465031.97257904]\n",
            " [26258806.74482447 34404080.68167185]]\n",
            "\n",
            " [[28002576]\n",
            " [39688652]\n",
            " [54265409]\n",
            " ...\n",
            " [45022611]\n",
            " [35465031]\n",
            " [34404080]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. Train a support vector machine using the training set obtained from above exerciseyou’re yourdataset has multiple classes, take any two classes for this exercise"
      ],
      "metadata": {
        "id": "iz7-NUa9WalN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_bins=4\n",
        "\n",
        "data['embed_1_b'] = pd.cut(data['embed_1'], num_bins)\n",
        "data['embed_12_b'] = pd.cut(data['embed_12'], num_bins)\n",
        "\n",
        "\n",
        "X = data['embed_1']\n",
        "y = data['embed_12']\n",
        "X = X.values.reshape(-1, 1)\n",
        "y = y.values.reshape(-1, 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "label_encoder = LabelEncoder()\n",
        "X_train_encoded = label_encoder.fit_transform(X_train)\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "X_test_encoded = label_encoder.fit_transform(X_test)\n",
        "X_test_encoded=X_train_encoded.reshape(-1, 1)\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "y_test_encoded=y_train_encoded.reshape(-1, 1)\n",
        "X_train_encoded=X_train_encoded.reshape(-1, 1)\n",
        "y_train_encoded= y_train_encoded.reshape(-1, 1)\n",
        "\n",
        "\n",
        "clf = svm.SVC()\n",
        "\n",
        "# Train the SVM classifier\n",
        "clf.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "# Get the support vectors\n",
        "support_vectors = clf.support_vectors_\n",
        "\n",
        "# Study the support vectors\n",
        "print(\"Number of support vectors:\", len(support_vectors))\n",
        "print(\"Support Vectors:\\n\", support_vectors)\n"
      ],
      "metadata": {
        "id": "lg9_N3VoN2ZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e8d92c-dc5c-4636-cf21-19cf40124071"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of support vectors: 898\n",
            "Support Vectors:\n",
            " [[212.]\n",
            " [139.]\n",
            " [667.]\n",
            " [667.]\n",
            " [220.]\n",
            " [194.]\n",
            " [547.]\n",
            " [800.]\n",
            " [169.]\n",
            " [602.]\n",
            " [626.]\n",
            " [786.]\n",
            " [629.]\n",
            " [130.]\n",
            " [496.]\n",
            " [484.]\n",
            " [569.]\n",
            " [214.]\n",
            " [704.]\n",
            " [279.]\n",
            " [320.]\n",
            " [458.]\n",
            " [597.]\n",
            " [ 81.]\n",
            " [ 63.]\n",
            " [567.]\n",
            " [571.]\n",
            " [121.]\n",
            " [591.]\n",
            " [291.]\n",
            " [ 90.]\n",
            " [152.]\n",
            " [637.]\n",
            " [499.]\n",
            " [384.]\n",
            " [316.]\n",
            " [265.]\n",
            " [503.]\n",
            " [222.]\n",
            " [300.]\n",
            " [607.]\n",
            " [463.]\n",
            " [317.]\n",
            " [415.]\n",
            " [399.]\n",
            " [767.]\n",
            " [719.]\n",
            " [151.]\n",
            " [417.]\n",
            " [354.]\n",
            " [355.]\n",
            " [201.]\n",
            " [556.]\n",
            " [715.]\n",
            " [327.]\n",
            " [541.]\n",
            " [712.]\n",
            " [552.]\n",
            " [603.]\n",
            " [243.]\n",
            " [329.]\n",
            " [682.]\n",
            " [368.]\n",
            " [ 35.]\n",
            " [118.]\n",
            " [221.]\n",
            " [469.]\n",
            " [275.]\n",
            " [557.]\n",
            " [732.]\n",
            " [732.]\n",
            " [598.]\n",
            " [527.]\n",
            " [527.]\n",
            " [426.]\n",
            " [114.]\n",
            " [462.]\n",
            " [696.]\n",
            " [490.]\n",
            " [684.]\n",
            " [ 66.]\n",
            " [647.]\n",
            " [ 92.]\n",
            " [123.]\n",
            " [366.]\n",
            " [366.]\n",
            " [653.]\n",
            " [751.]\n",
            " [483.]\n",
            " [170.]\n",
            " [655.]\n",
            " [730.]\n",
            " [727.]\n",
            " [190.]\n",
            " [563.]\n",
            " [332.]\n",
            " [332.]\n",
            " [695.]\n",
            " [422.]\n",
            " [215.]\n",
            " [100.]\n",
            " [688.]\n",
            " [115.]\n",
            " [622.]\n",
            " [627.]\n",
            " [627.]\n",
            " [633.]\n",
            " [213.]\n",
            " [640.]\n",
            " [739.]\n",
            " [621.]\n",
            " [568.]\n",
            " [472.]\n",
            " [165.]\n",
            " [737.]\n",
            " [656.]\n",
            " [ 51.]\n",
            " [702.]\n",
            " [103.]\n",
            " [560.]\n",
            " [560.]\n",
            " [322.]\n",
            " [370.]\n",
            " [531.]\n",
            " [723.]\n",
            " [721.]\n",
            " [566.]\n",
            " [741.]\n",
            " [706.]\n",
            " [551.]\n",
            " [592.]\n",
            " [284.]\n",
            " [369.]\n",
            " [315.]\n",
            " [697.]\n",
            " [753.]\n",
            " [694.]\n",
            " [477.]\n",
            " [783.]\n",
            " [836.]\n",
            " [542.]\n",
            " [717.]\n",
            " [540.]\n",
            " [628.]\n",
            " [628.]\n",
            " [245.]\n",
            " [619.]\n",
            " [516.]\n",
            " [564.]\n",
            " [341.]\n",
            " [ 62.]\n",
            " [825.]\n",
            " [681.]\n",
            " [461.]\n",
            " [164.]\n",
            " [686.]\n",
            " [686.]\n",
            " [785.]\n",
            " [596.]\n",
            " [613.]\n",
            " [255.]\n",
            " [161.]\n",
            " [506.]\n",
            " [138.]\n",
            " [274.]\n",
            " [748.]\n",
            " [671.]\n",
            " [460.]\n",
            " [650.]\n",
            " [205.]\n",
            " [441.]\n",
            " [532.]\n",
            " [128.]\n",
            " [687.]\n",
            " [687.]\n",
            " [ 71.]\n",
            " [639.]\n",
            " [812.]\n",
            " [714.]\n",
            " [610.]\n",
            " [810.]\n",
            " [185.]\n",
            " [187.]\n",
            " [775.]\n",
            " [246.]\n",
            " [252.]\n",
            " [272.]\n",
            " [580.]\n",
            " [348.]\n",
            " [348.]\n",
            " [665.]\n",
            " [372.]\n",
            " [382.]\n",
            " [404.]\n",
            " [521.]\n",
            " [223.]\n",
            " [110.]\n",
            " [616.]\n",
            " [237.]\n",
            " [584.]\n",
            " [680.]\n",
            " [700.]\n",
            " [829.]\n",
            " [238.]\n",
            " [351.]\n",
            " [ 98.]\n",
            " [352.]\n",
            " [728.]\n",
            " [146.]\n",
            " [ 46.]\n",
            " [136.]\n",
            " [ 96.]\n",
            " [216.]\n",
            " [270.]\n",
            " [620.]\n",
            " [578.]\n",
            " [703.]\n",
            " [632.]\n",
            " [632.]\n",
            " [302.]\n",
            " [393.]\n",
            " [752.]\n",
            " [595.]\n",
            " [172.]\n",
            " [ 70.]\n",
            " [575.]\n",
            " [575.]\n",
            " [575.]\n",
            " [575.]\n",
            " [575.]\n",
            " [189.]\n",
            " [488.]\n",
            " [ 20.]\n",
            " [615.]\n",
            " [371.]\n",
            " [  5.]\n",
            " [662.]\n",
            " [135.]\n",
            " [111.]\n",
            " [321.]\n",
            " [599.]\n",
            " [509.]\n",
            " [168.]\n",
            " [487.]\n",
            " [744.]\n",
            " [514.]\n",
            " [ 94.]\n",
            " [555.]\n",
            " [196.]\n",
            " [756.]\n",
            " [750.]\n",
            " [439.]\n",
            " [439.]\n",
            " [439.]\n",
            " [820.]\n",
            " [177.]\n",
            " [ 60.]\n",
            " [296.]\n",
            " [482.]\n",
            " [443.]\n",
            " [234.]\n",
            " [345.]\n",
            " [289.]\n",
            " [276.]\n",
            " [625.]\n",
            " [724.]\n",
            " [412.]\n",
            " [160.]\n",
            " [181.]\n",
            " [262.]\n",
            " [251.]\n",
            " [816.]\n",
            " [ 85.]\n",
            " [664.]\n",
            " [278.]\n",
            " [644.]\n",
            " [769.]\n",
            " [356.]\n",
            " [733.]\n",
            " [486.]\n",
            " [492.]\n",
            " [178.]\n",
            " [713.]\n",
            " [471.]\n",
            " [105.]\n",
            " [242.]\n",
            " [638.]\n",
            " [ 95.]\n",
            " [691.]\n",
            " [815.]\n",
            " [666.]\n",
            " [122.]\n",
            " [ 49.]\n",
            " [ 79.]\n",
            " [263.]\n",
            " [641.]\n",
            " [104.]\n",
            " [ 86.]\n",
            " [307.]\n",
            " [150.]\n",
            " [658.]\n",
            " [323.]\n",
            " [799.]\n",
            " [247.]\n",
            " [508.]\n",
            " [758.]\n",
            " [391.]\n",
            " [809.]\n",
            " [ 36.]\n",
            " [572.]\n",
            " [379.]\n",
            " [755.]\n",
            " [582.]\n",
            " [271.]\n",
            " [211.]\n",
            " [433.]\n",
            " [184.]\n",
            " [188.]\n",
            " [126.]\n",
            " [605.]\n",
            " [502.]\n",
            " [507.]\n",
            " [374.]\n",
            " [374.]\n",
            " [ 97.]\n",
            " [522.]\n",
            " [754.]\n",
            " [224.]\n",
            " [107.]\n",
            " [646.]\n",
            " [670.]\n",
            " [579.]\n",
            " [ 78.]\n",
            " [779.]\n",
            " [229.]\n",
            " [149.]\n",
            " [601.]\n",
            " [553.]\n",
            " [821.]\n",
            " [593.]\n",
            " [594.]\n",
            " [594.]\n",
            " [497.]\n",
            " [311.]\n",
            " [476.]\n",
            " [449.]\n",
            " [449.]\n",
            " [576.]\n",
            " [760.]\n",
            " [773.]\n",
            " [127.]\n",
            " [207.]\n",
            " [ 76.]\n",
            " [ 88.]\n",
            " [ 74.]\n",
            " [611.]\n",
            " [410.]\n",
            " [794.]\n",
            " [802.]\n",
            " [660.]\n",
            " [357.]\n",
            " [689.]\n",
            " [689.]\n",
            " [537.]\n",
            " [475.]\n",
            " [ 58.]\n",
            " [659.]\n",
            " [659.]\n",
            " [367.]\n",
            " [743.]\n",
            " [179.]\n",
            " [217.]\n",
            " [452.]\n",
            " [144.]\n",
            " [186.]\n",
            " [395.]\n",
            " [ 48.]\n",
            " [485.]\n",
            " [108.]\n",
            " [ 83.]\n",
            " [604.]\n",
            " [ 91.]\n",
            " [489.]\n",
            " [489.]\n",
            " [308.]\n",
            " [570.]\n",
            " [528.]\n",
            " [324.]\n",
            " [495.]\n",
            " [768.]\n",
            " [427.]\n",
            " [309.]\n",
            " [437.]\n",
            " [465.]\n",
            " [102.]\n",
            " [718.]\n",
            " [718.]\n",
            " [718.]\n",
            " [549.]\n",
            " [766.]\n",
            " [257.]\n",
            " [818.]\n",
            " [180.]\n",
            " [784.]\n",
            " [156.]\n",
            " [705.]\n",
            " [588.]\n",
            " [833.]\n",
            " [ 84.]\n",
            " [ 84.]\n",
            " [342.]\n",
            " [342.]\n",
            " [342.]\n",
            " [612.]\n",
            " [651.]\n",
            " [303.]\n",
            " [529.]\n",
            " [ 47.]\n",
            " [701.]\n",
            " [701.]\n",
            " [701.]\n",
            " [208.]\n",
            " [ 77.]\n",
            " [764.]\n",
            " [230.]\n",
            " [ 42.]\n",
            " [824.]\n",
            " [562.]\n",
            " [268.]\n",
            " [624.]\n",
            " [ 31.]\n",
            " [ 68.]\n",
            " [231.]\n",
            " [209.]\n",
            " [306.]\n",
            " [772.]\n",
            " [419.]\n",
            " [419.]\n",
            " [822.]\n",
            " [ 29.]\n",
            " [349.]\n",
            " [ 52.]\n",
            " [ 52.]\n",
            " [ 52.]\n",
            " [183.]\n",
            " [133.]\n",
            " [250.]\n",
            " [429.]\n",
            " [429.]\n",
            " [561.]\n",
            " [203.]\n",
            " [ 61.]\n",
            " [191.]\n",
            " [ 55.]\n",
            " [421.]\n",
            " [193.]\n",
            " [464.]\n",
            " [155.]\n",
            " [590.]\n",
            " [538.]\n",
            " [298.]\n",
            " [806.]\n",
            " [112.]\n",
            " [425.]\n",
            " [157.]\n",
            " [535.]\n",
            " [ 64.]\n",
            " [117.]\n",
            " [218.]\n",
            " [113.]\n",
            " [530.]\n",
            " [389.]\n",
            " [722.]\n",
            " [ 57.]\n",
            " [219.]\n",
            " [762.]\n",
            " [147.]\n",
            " [283.]\n",
            " [282.]\n",
            " [450.]\n",
            " [614.]\n",
            " [ 39.]\n",
            " [544.]\n",
            " [290.]\n",
            " [256.]\n",
            " [403.]\n",
            " [742.]\n",
            " [254.]\n",
            " [  2.]\n",
            " [418.]\n",
            " [511.]\n",
            " [511.]\n",
            " [791.]\n",
            " [248.]\n",
            " [240.]\n",
            " [364.]\n",
            " [771.]\n",
            " [731.]\n",
            " [792.]\n",
            " [162.]\n",
            " [454.]\n",
            " [ 93.]\n",
            " [777.]\n",
            " [346.]\n",
            " [759.]\n",
            " [166.]\n",
            " [281.]\n",
            " [294.]\n",
            " [286.]\n",
            " [635.]\n",
            " [745.]\n",
            " [587.]\n",
            " [197.]\n",
            " [145.]\n",
            " [260.]\n",
            " [673.]\n",
            " [457.]\n",
            " [457.]\n",
            " [565.]\n",
            " [414.]\n",
            " [414.]\n",
            " [158.]\n",
            " [801.]\n",
            " [438.]\n",
            " [447.]\n",
            " [447.]\n",
            " [536.]\n",
            " [716.]\n",
            " [512.]\n",
            " [606.]\n",
            " [513.]\n",
            " [513.]\n",
            " [513.]\n",
            " [513.]\n",
            " [513.]\n",
            " [ 99.]\n",
            " [631.]\n",
            " [ 65.]\n",
            " [423.]\n",
            " [652.]\n",
            " [435.]\n",
            " [132.]\n",
            " [132.]\n",
            " [661.]\n",
            " [746.]\n",
            " [163.]\n",
            " [796.]\n",
            " [176.]\n",
            " [411.]\n",
            " [757.]\n",
            " [ 67.]\n",
            " [525.]\n",
            " [726.]\n",
            " [204.]\n",
            " [519.]\n",
            " [ 25.]\n",
            " [408.]\n",
            " [683.]\n",
            " [677.]\n",
            " [636.]\n",
            " [787.]\n",
            " [559.]\n",
            " [778.]\n",
            " [811.]\n",
            " [830.]\n",
            " [396.]\n",
            " [657.]\n",
            " [405.]\n",
            " [720.]\n",
            " [803.]\n",
            " [808.]\n",
            " [ 75.]\n",
            " [617.]\n",
            " [831.]\n",
            " [167.]\n",
            " [235.]\n",
            " [609.]\n",
            " [398.]\n",
            " [834.]\n",
            " [804.]\n",
            " [515.]\n",
            " [699.]\n",
            " [534.]\n",
            " [478.]\n",
            " [202.]\n",
            " [124.]\n",
            " [249.]\n",
            " [173.]\n",
            " [173.]\n",
            " [618.]\n",
            " [ 80.]\n",
            " [402.]\n",
            " [453.]\n",
            " [747.]\n",
            " [827.]\n",
            " [710.]\n",
            " [788.]\n",
            " [823.]\n",
            " [266.]\n",
            " [206.]\n",
            " [736.]\n",
            " [510.]\n",
            " [709.]\n",
            " [734.]\n",
            " [546.]\n",
            " [526.]\n",
            " [200.]\n",
            " [239.]\n",
            " [192.]\n",
            " [643.]\n",
            " [642.]\n",
            " [523.]\n",
            " [ 12.]\n",
            " [143.]\n",
            " [574.]\n",
            " [301.]\n",
            " [305.]\n",
            " [749.]\n",
            " [690.]\n",
            " [813.]\n",
            " [241.]\n",
            " [480.]\n",
            " [285.]\n",
            " [581.]\n",
            " [581.]\n",
            " [293.]\n",
            " [501.]\n",
            " [630.]\n",
            " [ 87.]\n",
            " [269.]\n",
            " [148.]\n",
            " [654.]\n",
            " [154.]\n",
            " [154.]\n",
            " [ 72.]\n",
            " [807.]\n",
            " [109.]\n",
            " [381.]\n",
            " [711.]\n",
            " [805.]\n",
            " [634.]\n",
            " [267.]\n",
            " [280.]\n",
            " [ 41.]\n",
            " [134.]\n",
            " [826.]\n",
            " [675.]\n",
            " [153.]\n",
            " [153.]\n",
            " [337.]\n",
            " [ 73.]\n",
            " [782.]\n",
            " [304.]\n",
            " [ 45.]\n",
            " [ 26.]\n",
            " [141.]\n",
            " [377.]\n",
            " [819.]\n",
            " [227.]\n",
            " [470.]\n",
            " [795.]\n",
            " [795.]\n",
            " [225.]\n",
            " [774.]\n",
            " [797.]\n",
            " [781.]\n",
            " [434.]\n",
            " [319.]\n",
            " [729.]\n",
            " [790.]\n",
            " [467.]\n",
            " [798.]\n",
            " [174.]\n",
            " [ 18.]\n",
            " [244.]\n",
            " [444.]\n",
            " [131.]\n",
            " [ 27.]\n",
            " [ 11.]\n",
            " [577.]\n",
            " [261.]\n",
            " [198.]\n",
            " [ 40.]\n",
            " [623.]\n",
            " [159.]\n",
            " [ 28.]\n",
            " [233.]\n",
            " [ 38.]\n",
            " [679.]\n",
            " [493.]\n",
            " [428.]\n",
            " [ 22.]\n",
            " [ 22.]\n",
            " [765.]\n",
            " [259.]\n",
            " [491.]\n",
            " [ 53.]\n",
            " [ 53.]\n",
            " [ 53.]\n",
            " [554.]\n",
            " [586.]\n",
            " [517.]\n",
            " [676.]\n",
            " [ 23.]\n",
            " [707.]\n",
            " [312.]\n",
            " [668.]\n",
            " [340.]\n",
            " [ 82.]\n",
            " [314.]\n",
            " [  6.]\n",
            " [336.]\n",
            " [817.]\n",
            " [350.]\n",
            " [481.]\n",
            " [380.]\n",
            " [725.]\n",
            " [832.]\n",
            " [678.]\n",
            " [672.]\n",
            " [828.]\n",
            " [385.]\n",
            " [776.]\n",
            " [ 13.]\n",
            " [420.]\n",
            " [446.]\n",
            " [390.]\n",
            " [373.]\n",
            " [  9.]\n",
            " [  9.]\n",
            " [137.]\n",
            " [361.]\n",
            " [397.]\n",
            " [735.]\n",
            " [362.]\n",
            " [ 16.]\n",
            " [ 16.]\n",
            " [330.]\n",
            " [386.]\n",
            " [387.]\n",
            " [400.]\n",
            " [334.]\n",
            " [473.]\n",
            " [ 15.]\n",
            " [401.]\n",
            " [363.]\n",
            " [338.]\n",
            " [394.]\n",
            " [353.]\n",
            " [789.]\n",
            " [692.]\n",
            " [171.]\n",
            " [299.]\n",
            " [182.]\n",
            " [780.]\n",
            " [430.]\n",
            " [119.]\n",
            " [474.]\n",
            " [814.]\n",
            " [392.]\n",
            " [347.]\n",
            " [  8.]\n",
            " [253.]\n",
            " [674.]\n",
            " [  4.]\n",
            " [  4.]\n",
            " [273.]\n",
            " [698.]\n",
            " [359.]\n",
            " [407.]\n",
            " [  3.]\n",
            " [456.]\n",
            " [175.]\n",
            " [600.]\n",
            " [383.]\n",
            " [360.]\n",
            " [409.]\n",
            " [793.]\n",
            " [ 37.]\n",
            " [376.]\n",
            " [608.]\n",
            " [ 34.]\n",
            " [228.]\n",
            " [  1.]\n",
            " [  1.]\n",
            " [545.]\n",
            " [432.]\n",
            " [589.]\n",
            " [344.]\n",
            " [533.]\n",
            " [406.]\n",
            " [ 19.]\n",
            " [763.]\n",
            " [504.]\n",
            " [539.]\n",
            " [325.]\n",
            " [  0.]\n",
            " [  0.]\n",
            " [297.]\n",
            " [424.]\n",
            " [318.]\n",
            " [277.]\n",
            " [292.]\n",
            " [101.]\n",
            " [455.]\n",
            " [ 14.]\n",
            " [685.]\n",
            " [ 32.]\n",
            " [466.]\n",
            " [440.]\n",
            " [ 69.]\n",
            " [573.]\n",
            " [585.]\n",
            " [413.]\n",
            " [106.]\n",
            " [199.]\n",
            " [ 30.]\n",
            " [500.]\n",
            " [142.]\n",
            " [236.]\n",
            " [375.]\n",
            " [129.]\n",
            " [125.]\n",
            " [310.]\n",
            " [326.]\n",
            " [518.]\n",
            " [120.]\n",
            " [258.]\n",
            " [761.]\n",
            " [693.]\n",
            " [ 54.]\n",
            " [ 54.]\n",
            " [343.]\n",
            " [210.]\n",
            " [313.]\n",
            " [669.]\n",
            " [442.]\n",
            " [494.]\n",
            " [451.]\n",
            " [448.]\n",
            " [365.]\n",
            " [431.]\n",
            " [ 33.]\n",
            " [288.]\n",
            " [388.]\n",
            " [232.]\n",
            " [ 56.]\n",
            " [583.]\n",
            " [ 17.]\n",
            " [738.]\n",
            " [558.]\n",
            " [331.]\n",
            " [416.]\n",
            " [335.]\n",
            " [468.]\n",
            " [436.]\n",
            " [195.]\n",
            " [459.]\n",
            " [524.]\n",
            " [116.]\n",
            " [226.]\n",
            " [663.]\n",
            " [140.]\n",
            " [505.]\n",
            " [ 44.]\n",
            " [295.]\n",
            " [550.]\n",
            " [649.]\n",
            " [  7.]\n",
            " [708.]\n",
            " [264.]\n",
            " [ 43.]\n",
            " [ 43.]\n",
            " [770.]\n",
            " [358.]\n",
            " [648.]\n",
            " [520.]\n",
            " [339.]\n",
            " [ 59.]\n",
            " [ 50.]\n",
            " [328.]\n",
            " [287.]\n",
            " [ 24.]\n",
            " [378.]\n",
            " [ 21.]\n",
            " [333.]\n",
            " [ 10.]\n",
            " [740.]\n",
            " [740.]\n",
            " [445.]\n",
            " [645.]\n",
            " [ 89.]\n",
            " [498.]\n",
            " [835.]\n",
            " [543.]\n",
            " [479.]\n",
            " [479.]\n",
            " [548.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2.support_vectors_A2. Test the accuracy of the SVM using the test set obtained from above exercise. Following code for help."
      ],
      "metadata": {
        "id": "2pTRrZamWgXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question A2\n",
        "clf.score(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dkd6klR9buo",
        "outputId": "2519cc65-dbcf-47d9-d61d-33647e221acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7417923691215617"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. Use the Predict function of SVC classifier to study the output values of the classifier. Relate the output value to the class value predicted. Test the accuracy of the SVM, with your own logic of class determination and comparing against the class labels, using the test set obtained from above exercise."
      ],
      "metadata": {
        "id": "6SiuDnEzWkp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question A3\n",
        "clf.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHQA1uMO9jKI",
        "outputId": "46e37731-a437-41ab-d078-b3455f6a2376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4241, 3390, 5132, 5040, 3006, 5605, 5290, 1707, 5920, 1032, 4550,\n",
              "       4933, 7642, 6159, 4599, 4291, 4859, 6840, 6192, 6300, 5449, 3394,\n",
              "       4710, 5654, 5312, 6945, 2696, 5967, 5884, 7160, 3390, 6650, 4552,\n",
              "       4955, 6926, 3424, 4104, 3243, 7596, 6045, 5620, 3064, 3924, 2875,\n",
              "       5913, 2420, 4555, 4378, 5953, 8817, 4447, 2634, 3916, 3027, 5916,\n",
              "       3202, 5613, 3968, 5788, 3072, 6146, 4212, 4029, 5864, 3664, 3530,\n",
              "       4467, 5256, 4958, 6837, 6198, 4022, 2634, 4656, 4404, 4196, 4447,\n",
              "       3318, 4846, 5132, 5061, 3638, 5459, 2875, 6840, 5234, 5413, 6481,\n",
              "       4292, 5517, 6650, 3789, 6636, 6146, 4802, 3352, 5705, 4958, 2450,\n",
              "       4072, 1860, 4566, 6837, 4356, 1032, 5701, 5864, 5599, 4628, 6344,\n",
              "       4264, 6837, 3387, 4342, 3816, 1860, 6494, 6945, 4461, 6098, 5748,\n",
              "       4710, 4707, 3992, 4848, 4920, 5469, 1707, 3992, 6187, 3282, 5808,\n",
              "       3376, 6945, 6146, 3682, 3935, 3546, 5506, 3031, 7216, 2398, 6281,\n",
              "       7637, 5792, 4958, 5083, 4072, 3073, 5403, 4744, 5095, 5846, 2049,\n",
              "       2285, 5483, 6281, 5821, 2285, 4719, 6192, 6182, 6337, 4502, 4153,\n",
              "       4558, 3546, 1644, 4497, 4646, 5715, 4196, 3073, 2233, 3471, 4736,\n",
              "       8822, 6561, 4391, 7614, 5095, 3154, 1032, 3714, 5715, 4387, 1633,\n",
              "       3664, 6970, 3565, 5864, 5764, 5568, 3546, 6523, 3006, 6655, 7219,\n",
              "       4482, 6561, 3606, 4881, 5483, 3749, 7160, 5444, 3482, 3249, 3686,\n",
              "       5715, 5912, 3073, 7492, 3916, 2517, 6300, 6937, 3864, 2860, 2285,\n",
              "       3711, 3840, 6071, 3161, 2486, 6937, 3376, 1480, 2377, 2528, 5413,\n",
              "       3764, 3621, 4635, 3132, 7316, 4599, 6926, 3320, 2854, 5864, 3126,\n",
              "       5117, 6115, 6691, 3859, 3054, 4387, 4745, 7160, 7259, 8817, 7361,\n",
              "       5083, 6337, 7101, 4705, 5764, 3822, 5789, 5856, 3894, 4925, 4466,\n",
              "       4296, 3640, 4995, 1341, 2694, 4296, 2875, 5207, 4736, 3178, 6458,\n",
              "       5587, 7008, 6227, 2735, 4707, 4958, 5856, 3700, 5764, 6494, 7219,\n",
              "       4955, 4847, 6344, 6146, 6840, 4365, 6456, 4000, 5520, 5291, 6650,\n",
              "       5764, 1360, 3700, 6494, 4291, 5117, 2785, 4703, 3713, 5913, 7042,\n",
              "       5503, 5912, 9202, 5469, 6709, 5137, 4958, 4846, 5195, 3978, 8695,\n",
              "       5590, 5436, 6834, 7378, 6691, 3387, 4649, 4325, 6192, 6828, 2379,\n",
              "       7496, 2028, 4541, 1966, 5979, 2620, 1966, 4705, 6937])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. Experiment with various kernel functions (‘linear’, ‘poly’, ‘rbf’&‘sigmoid’) to train and test the accuracy of the models."
      ],
      "metadata": {
        "id": "k4SjptOTWsS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question A4\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-QYgWf9qX2",
        "outputId": "8f1bccbf-7c93-4df7-faac-2c408c35ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5749778172138421"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IdXxzyU944Y",
        "outputId": "a8b88714-daa3-4184-ff54-c8373f910696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5749778172138421"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8odmn0s9_O0",
        "outputId": "918443ca-e2bd-4bef-ad42-1d715a6cfcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03992901508429459"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = svm.SVC(kernel='sigmoid')\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y0PD_cU-FRg",
        "outputId": "4c162754-875b-4af1-fb18-3e1c4dab8bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005323868677905945"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}